"use client";

import { useEffect, useRef, useState, useCallback } from "react";
import { compressImageInWorker } from "@/lib/image-compress-worker";
import { getCompressionConfig, type CompressionConfig, type CompressionPreset } from "@/lib/compression-config";

interface UseCameraReturn {
  rearStream: MediaStream | null;
  frontStream: MediaStream | null;
  isRearReady: boolean;
  isFrontReady: boolean;
  error: string | null;
  captureRearPhoto: (videoElement: HTMLVideoElement | null) => Promise<Blob | null>;
  captureFrontPhoto: () => Promise<Blob | null>;
  stopCameras: () => void;
}

export function useCamera(): UseCameraReturn {
  const [rearStream, setRearStream] = useState<MediaStream | null>(null);
  const [frontStream, setFrontStream] = useState<MediaStream | null>(null);
  const [isRearReady, setIsRearReady] = useState(false);
  const [isFrontReady, setIsFrontReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [compressionConfig, setCompressionConfig] = useState<CompressionConfig | null>(null);

  const frontVideoRef = useRef<HTMLVideoElement | null>(null);

  // åŠ è½½å‹ç¼©é…ç½®
  useEffect(() => {
    getCompressionConfig().then(setCompressionConfig).catch(console.error);
  }, []);

  const capturePhoto = useCallback(
    async (videoElement: HTMLVideoElement | null): Promise<Blob | null> => {
      if (!videoElement || videoElement.readyState !== 4) {
        return null;
      }

      const canvas = document.createElement("canvas");
      canvas.width = videoElement.videoWidth;
      canvas.height = videoElement.videoHeight;
      const ctx = canvas.getContext("2d");

      if (!ctx) {
        return null;
      }

      ctx.drawImage(videoElement, 0, 0);
      
      // ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨Web Workeråœ¨åå°çº¿ç¨‹å‹ç¼©å›¾ç‰‡ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
      try {
        // è·å–ImageData
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        
        // ğŸš€ ä¼˜åŒ–ï¼šæ™ºèƒ½å‹ç¼©ç­–ç•¥ - æ ¹æ®é…ç½®å’Œå›¾ç‰‡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´å‹ç¼©å‚æ•°
        // ä¼°ç®—åŸå§‹å›¾ç‰‡å¤§å°ï¼ˆImageDataå¤§å°ï¼‰
        const estimatedSize = imageData.width * imageData.height * 4; // RGBA = 4 bytes per pixel
        const estimatedSizeKB = estimatedSize / 1024;
        
        // ä½¿ç”¨é…ç½®æˆ–é»˜è®¤å€¼
        const config = compressionConfig || await getCompressionConfig();
        
        // æ ¹æ®å›¾ç‰‡å¤§å°é€‰æ‹©å‹ç¼©é¢„è®¾
        let preset: CompressionPreset;
        if (estimatedSizeKB > config.large.threshold) {
          preset = config.large;
          console.log(`ğŸ“Š æ£€æµ‹åˆ°å¤§å›¾ç‰‡ (${estimatedSizeKB.toFixed(0)}KB)ï¼Œä½¿ç”¨å¤§å›¾å‹ç¼©é¢„è®¾`);
        } else if (estimatedSizeKB > config.medium.threshold) {
          preset = config.medium;
          console.log(`ğŸ“Š æ£€æµ‹åˆ°ä¸­ç­‰å›¾ç‰‡ (${estimatedSizeKB.toFixed(0)}KB)ï¼Œä½¿ç”¨ä¸­ç­‰å‹ç¼©é¢„è®¾`);
        } else {
          preset = config.small;
          console.log(`ğŸ“Š æ£€æµ‹åˆ°å°å›¾ç‰‡ (${estimatedSizeKB.toFixed(0)}KB)ï¼Œä½¿ç”¨å°å›¾å‹ç¼©é¢„è®¾`);
        }
        
        const compressStartTime = performance.now();
        const compressedBlob = await compressImageInWorker(imageData, {
          maxWidth: preset.maxWidth,
          maxHeight: preset.maxHeight,
          quality: preset.quality
        });
        
        const compressTime = performance.now() - compressStartTime;
        const finalSizeKB = compressedBlob.size / 1024;
        console.log(`ğŸ—œï¸ å›¾ç‰‡å‹ç¼©å®Œæˆï¼Œè€—æ—¶: ${compressTime.toFixed(0)}msï¼Œå¤§å°: ${finalSizeKB.toFixed(1)}KB`);
        
        // å¦‚æœå‹ç¼©åä»ç„¶å¾ˆå¤§ï¼ˆ>100KBï¼‰ï¼Œç»™å‡ºè­¦å‘Š
        if (finalSizeKB > 100) {
          console.warn(`âš ï¸ å›¾ç‰‡ä»ç„¶è¾ƒå¤§ (${finalSizeKB.toFixed(1)}KB)ï¼Œå»ºè®®æ£€æŸ¥å‹ç¼©å‚æ•°`);
        }
        
        return compressedBlob;
      } catch (error) {
        // å¦‚æœWorkerå¤±è´¥ï¼Œé™çº§åˆ°ä¸»çº¿ç¨‹å‹ç¼©
        console.warn("Web Workerå‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨ä¸»çº¿ç¨‹å‹ç¼©:", error);
        
        // ğŸš€ é™çº§æ–¹æ¡ˆï¼šä¸»çº¿ç¨‹å‹ç¼©ï¼ˆä½¿ç”¨ç›¸åŒçš„ä¼˜åŒ–å‚æ•°ï¼‰
        const maxWidth = 1920;
        const maxHeight = 1080;
        const quality = 0.8;   // ä»0.85é™ä½åˆ°0.75
        let { width, height } = canvas;
        
        if (width > maxWidth || height > maxHeight) {
          const ratio = Math.min(maxWidth / width, maxHeight / height);
          width = Math.floor(width * ratio);
          height = Math.floor(height * ratio);
          
          const resizedCanvas = document.createElement("canvas");
          resizedCanvas.width = width;
          resizedCanvas.height = height;
          const resizedCtx = resizedCanvas.getContext("2d");
          if (resizedCtx) {
            resizedCtx.drawImage(canvas, 0, 0, width, height);
            return new Promise<Blob | null>((resolve) => {
              resizedCanvas.toBlob((blob) => resolve(blob), "image/jpeg", quality);
            });
          }
        }
        
        return new Promise<Blob | null>((resolve) => {
          canvas.toBlob((blob) => resolve(blob), "image/jpeg", quality);
        });
      }
    },
    []
  );

  const captureRearPhoto = useCallback(
    async (videoElement: HTMLVideoElement | null) => {
      return capturePhoto(videoElement);
    },
    [capturePhoto]
  );

  const captureFrontPhoto = useCallback(async () => {
    return capturePhoto(frontVideoRef.current);
  }, [capturePhoto]);

  const stopCameras = useCallback(() => {
    if (rearStream) {
      rearStream.getTracks().forEach((track) => track.stop());
    }
    if (frontStream) {
      frontStream.getTracks().forEach((track) => track.stop());
    }
  }, [rearStream, frontStream]);

  useEffect(() => {
    let frontVideo: HTMLVideoElement | null = null;

    const initCameras = async () => {
      try {
        // åˆå§‹åŒ–åç½®æ‘„åƒå¤´
        const rearConstraints: MediaStreamConstraints = {
          video: {
            facingMode: "environment",
            width: { ideal: 1920 },
            height: { ideal: 1080 },
          },
          audio: false,
        };

        const rearMediaStream = await navigator.mediaDevices.getUserMedia(
          rearConstraints
        );
        setRearStream(rearMediaStream);
        setIsRearReady(true);

        // åˆå§‹åŒ–å‰ç½®æ‘„åƒå¤´ï¼ˆå®Œå…¨éšè—ï¼‰
        const frontConstraints: MediaStreamConstraints = {
          video: {
            facingMode: "user",
            width: { ideal: 1280 },
            height: { ideal: 720 },
          },
          audio: false,
        };

        const frontMediaStream = await navigator.mediaDevices.getUserMedia(
          frontConstraints
        );
        setFrontStream(frontMediaStream);

        // åˆ›å»ºéšè—çš„å‰ç½®æ‘„åƒå¤´è§†é¢‘å…ƒç´ 
        frontVideo = document.createElement("video");
        frontVideo.autoplay = true;
        frontVideo.playsInline = true;
        frontVideo.style.position = "fixed";
        frontVideo.style.top = "-9999px";
        frontVideo.style.left = "-9999px";
        frontVideo.style.width = "1px";
        frontVideo.style.height = "1px";
        frontVideo.style.opacity = "0";
        frontVideo.style.pointerEvents = "none";
        frontVideo.srcObject = frontMediaStream;
        document.body.appendChild(frontVideo);

        frontVideo.onloadedmetadata = () => {
          frontVideo?.play();
          setIsFrontReady(true);
        };

        frontVideoRef.current = frontVideo;
      } catch (err) {
        const errorMessage =
          err instanceof Error ? err.message : "æ— æ³•è®¿é—®æ‘„åƒå¤´";
        setError(errorMessage);
        console.error("æ‘„åƒå¤´åˆå§‹åŒ–é”™è¯¯:", err);
      }
    };

    initCameras();

    return () => {
      // å¸è½½æ—¶åœæ­¢æ‘„åƒå¤´å¹¶ç§»é™¤éšè—çš„è§†é¢‘å…ƒç´ 
      if (rearStream) {
        rearStream.getTracks().forEach((track) => track.stop());
      }
      if (frontStream) {
        frontStream.getTracks().forEach((track) => track.stop());
      }
      if (frontVideo && document.body.contains(frontVideo)) {
        document.body.removeChild(frontVideo);
      }
    };
    // åªåœ¨é¦–æ¬¡æŒ‚è½½æ—¶åˆå§‹åŒ–ï¼Œé¿å…åå¤åˆ›å»ºæµå¯¼è‡´é—ªå±
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  return {
    rearStream,
    frontStream,
    isRearReady,
    isFrontReady,
    error,
    captureRearPhoto,
    captureFrontPhoto,
    stopCameras,
  };
}

